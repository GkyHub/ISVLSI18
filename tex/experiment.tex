\section{Experiments}\label{sec:exp}

\input{table/device}

Experiments are carried out on the architecture introduced in Section~\ref{sec:hw}, with the scheduling strategy in section~\ref{sec:schedule} applied. We use a behavior level simulator to analyze the memory access and computation energy for running a certain network. Memory access dynamic energy cost, memory static energy cost and computation energy cost are considered in our model.

\subsection{Experiment setup}
The MAC array in the architecture is configured as an $8\times8\times8$ array running at 1GHz. This offers a peak performance of 1TOP/s. 8bit multiplication and 32bit accumulation is adopted in this model. Multiplication and addition energy is scaled down from the data in~\cite{mac_energy} to 22nm technology. 

The above configuration requires the read bandwidth of input/output buffer and weight buffer to be at least 64GB/s. We implement each buffer with 8 banks and each of them should offer 8GB/s read bandwidth. On-chip memory parameters are generated from NVSim~\cite{dong2014nvsim} with different memory size configuration. To achieve enough bandwidth, RRAM buffer bit width is configured as 256bit. 

The external memory parameter is generated from MICRON DDR4 power calculator~\cite{powercalc}. The generated dynamic I/O power is further converted to energy per read or write byte. In our experiment, we use 2 DDR chips as external memory because the bandwidth can support the configured MAC array with proposed schedule strategy and the size is enough. In order to reduce background power overhead, we use the least number of chips. All the detailed data and configuration is shown in Table~\ref{tab:device}. 

The buffer in the accumulator is also considered in our experiments. 4 types of buffer is chosen for design space exploration. Corresponding parameters are generated by NVSim and are shown in Table~\ref{tab:small_buf}.

\input{table/small_buf}

\subsection{Energy Cost Analysis}
We do experiments on all the combinations of the RAM configurations in Table \ref{tab:device} and \ref{tab:small_buf}, which means $5\times 5\times 5 = 125$ choices for a SRAM or RRAM based accelerator. The three schedule strategies in section~\ref{sec:schedule} is applied to each choice. Figure~\ref{fig:design_space} shows the experimental result with the convolution layers of VGG-11 network for 1 input. The energy cost for computation and DDR leakage is marked. These energy cost is the same for all the designs because the network is fixed and all the designs are computation bounded. So the processing time is a constant to all the designs. In general, the RRAM based design consumes less energy compared with an SRAM design of the same area. The minimal energy design for SRAM and RRAM costs 3086uJ and 2532uJ respectively, meaning that using RRAM is able to save 18\% system energy. The RRAM design is also 15\% smaller than the SRAM design. We also do experiments with the convolution layers of VGG-16 and AlexNet, where RRAM design saves 18\% and 12\% energy with 15\% and 75\% less on-chip RAM area compared with SRAM design.

\begin{figure*}[t]
  \centering
  \includegraphics[width=2\columnwidth]{fig/design_space.pdf}
  \vspace{-5pt}
  \caption{Design space exploration on different hardware choices and schedule strategies on the convolution layers of VGG-11 model. (a) SRAM weight buffer design. (b)RRAM weight buffer design.}
  \label{fig:design_space}
\end{figure*}

We examine the effect of the proposed hardware optimization and scheduling strategy. First, the loop order is the key effect to the RRAM based design, as shown in Figure~\ref{fig:design_space}(b). Note that some of the design points with the kernel first loop order are out of the figure because the energy cost is larger than 8000uJ. The large read energy of RRAM dominates the system energy as the capacity of RRAM increases. The reduction in DDR access cannot compensate for this overhead. Even on the smallest design, changing the loop order to pixel first will save at least 1/3 of the system energy cost. 

A breakdown on the on-chip buffer energy cost is shown in Figure~\ref{fig:breakdown}(a). The largest designs, in our experiment the designs with 4MB SRAM input/output buffer and 2MB SRAM (or 16MB RRAM) weight buffer are used. Here we only consider the read energy of input/output buffer and weight buffer and the dynamic energy of accumulation buffer. The write energy to input/output buffer and leakage energy are not affected by the accumulation buffer and thus not considered. Up to $96\%$ energy is saved for the RRAM based designs consider the overhead brough by the accumulation buffer. SRAM design also benefits from the change in loop order but not as effective as to the RRAM designs.

\begin{figure*}[t]
  \centering
  \includegraphics[width=1.8\columnwidth]{fig/breakdown.pdf}
  \vspace{-5pt}
  \caption{(a) On-chip buffer energy cost for a series of designs only differs in accumulation buffer size. (b) DDR access energy cost for a series of designs only differs in weight buffer size.}
  \label{fig:breakdown}
\end{figure*}

Second, fixing the weight on-chip helps the hardware fully utilize the on-chip RAM to reduce off-chip data transfer. As can be seen from Figure~\ref{fig:design_space}(b), using the pixel first loop order, the accelerator cannot benefit from larger on-chip buffer with single layer scheduling and cross layer scheduling. By fixing some of the network weights on-chip, the system energy cost is gradually reduced as the on-chip RAM size increases. 

A breakdown on the DDR transfer cost is shown in Figure~\ref{fig:breakdown}(b). All the designs implement no accumulation buffer and 1MB SRAM as input/output buffer. The single layer scheduling and cross layer scheduling can only achieve $6.4\%$ and $13.5\%$ energy saving respecitvely when the weight buffer increases from 1MB to 16MB. With the fix weight strategy, the energy saving is $98.5\%$. 